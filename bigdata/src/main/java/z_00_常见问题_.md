#mapReduce如何实现计算向数据迁移?
#OLTP VS OLAP ,lambda vs Kapper
#map Reduce vs spark
##编程模型
1.mapReduce:map,reduce
2.spark:RDD,多阶段灵活,DAG
##shuffle机制
[大数据处理架构Apache Spark设计]
![](.z_04_spark_02_对比MapReduce_images/a834bc72.png)

#spark比map Reduce快的原因?
[画图]
[](https://mp.weixin.qq.com/s?__biz=MzUxOTU5Mjk2OA==&mid=2247485991&idx=1&sn=79c9370801739813b4a624ae6fa55d6c&chksm=f9f60740ce818e56a18f8782d21d376d027928e434f065ac2c251df09d2d4283710679364639&scene=21#wechat_redirect)
[z_04_spark_01_拓扑.md]
[](https://www.zhihu.com/question/31930662)
##DAG(RDD+物理执行计划)
Spark计算比MapReduce快的根本原因在于DAG计算模型。一般而言，DAG相比Hadoop的MapReduce在大多数情况下可以减少shuffle次数。
Spark的DAGScheduler相当于一个改进版的MapReduce，如果计算不涉及与其他节点进行数据交换，Spark可以在内存中一次性完成这些操作，
也就是中间结果无须落盘，减少了磁盘IO的操作
##缓存机制
Spark支持将需要反复用到的中间数据给Cache到内存中，减少数据加载耗时
![](.z_04_spark_02_对比MapReduce_images/645130f0.png)
Spark是内存计算引擎，而MapReduce在计算的过程中，需要频繁落盘，因此，一般来说，相比MapReduce，Spark在执行性能上，更胜一筹
##多进程模型 vs 多线程模型
MapReduce采用了多进程模型，而Spark采用了多线程模型。多进程模型的好处是便于细粒度控制每个任务占用的资源，
但每次任务的启动都会消耗一定的启动时间。就是说MapReduce的Map Task和Reduce Task是进程级别的，
而Spark Task则是基于线程模型的，就是说mapreduce 中的 map 和 reduce 都是 jvm 进程，每次启动都需要重新申请资源，
消耗了不必要的时间
##checkpoint
不需要从头恢复
#spark stream vs flink
