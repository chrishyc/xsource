# HDFS问题清单
##架构
Master/Slave 架构
NameNode是集群的主节点，DataNode是集群的从节点
##文件单位
HDFS 中的文件在物理上是分块存储(block)的，块的大小可以通过配置参数来规定; Hadoop2.x版本中默认的block大小是128M;
##命令空间
命名空间(NameSpace)
文件系统名字空间的层次结构和大多数现有的文件系统类似:用户可以创建、删除、移动 或重命名文件。
Namenode 负责维护文件系统的名字空间，任何对文件系统名字空间或属性的修改都将被 Namenode 记录下来。
HDFS提供给客户单一个抽象目录树，访问形式:hdfs://namenode的hostname:port/test/input
hdfs://linux121:9000/test/input

##NameNode元数据管理
NameNode元数据管理
我们把目录结构及文件分块位置信息叫做元数据。
NameNode的元数据记录每一个文件所对应的block信息(block的id,以及所在的DataNode节点 的信息)

##DataNode数据存储
文件的各个 block 的具体存储管理由 DataNode 节点承担。一个block会有多个DataNode来存
储，DataNode会定时向NameNode来汇报自己持有的block信息

##副本机制
为了容错，文件的所有 block 都会有副本。每个文件的 block 大小和副本系数都是可配置的。应用 程序可以指定某个文件的副本数目。副本系数可以在文件创建的时候指定，也可以在之后改变。 副本数量默认是3个


##一次写入，多次读出
HDFS 是设计成适应一次写入，多次读出的场景，且不支持文件的随机修改。 (支持追加写入， 不只支持随机更新)
正因为如此，HDFS 适合用来做大数据分析的底层存储服务，并不适合用来做网盘等应用(修改不 方便，延迟大，网络开销大，成本太高

#hadoop问题清单

## docker搭建
[](https://kiwenlau.com/2016/06/12/160612-hadoop-cluster-docker-update/)


## 1.hadoop搭建
[](https://zhuanlan.zhihu.com/p/33117305)

## 启动命令
hadoop-daemon.sh start namenode
hadoop-daemon.sh start datanode

## web ui默认端口
http://localhost:9870/dfshealth.html#tab-overview
## 集群 webui
http://localhost:8088/cluster/nodelabels

## 排查hadoop错误信息
export HADOOP_ROOT_LOGGER=DEBUG,console



hadoop fs  -moveFromLocal  ./hadoop.txt /lagou/bigdata






#hbase问题清单

## hbase是什么?(感性认知)
[hbase docker搭建](https://www.rossontheway.com/2019/12/23/%E4%BD%BF%E7%94%A8Docker%E9%83%A8%E7%BD%B2HBase%E5%B9%B6%E4%BD%BF%E7%94%A8Java-API%E8%BF%9E%E6%8E%A5/)


## hbase需求?

## hbase方案?


## hbase模型:
names node
data node
客户端
block file
备份

## 读流程/写流程


## 使用
[访问hdfs](/Users/chris/workspace/xsource/bigdata/src/main/resources/Hadoop课程笔记.pdf)

#### 申请kerberos账号



## 热备份/冷备份
冷备发生在数据库已经正常关闭的情况下，将数据库文件拷贝到其他位置
热备是在数据库运行的情况下，采用归档方式备份数据
https://blog.csdn.net/meism5/article/details/104231570

## cdn是什么?idc是什么?云是什么?
https://www.zhihu.com/question/40534161

## 为什么要IDC?
https://zhuanlan.zhihu.com/p/78919493
IDC,服务器，宽带，ip,
IDC，服务器搭建，服务器管理，数据安全，传输速度
https://zhuanlan.zhihu.com/p/354339685






#spark问题清单
## spark 一期演化
1.spark是什么?干什么？有什么需求
[spark docker容器](https://tellyouwhat.cn/p/docker-build-spark-wordcount-app/#toc-heading-5)
2.spark怎么使用?
3.写一个可运行demo
4.理解简单的原理和组件
driver(main)
executor执行task

5.spark集群类型
单机,yarn,master/slave
6.
## rdd


#hive
Hive：借助Hive，用户可以编写SQL语句来查询HDFS上的结构化数据，SQL会被转化成MapReduce执行

[hive 使用](https://zhuanlan.zhihu.com/p/80166949)
[parquet格式](https://juejin.cn/post/6844903462572916743#heading-3)
#flink

#mapReduce

#Storm
Storm：Strom是一款实时计算框架，主要负责流处理


#scala使用
